# ğŸ“Š Incremental ML Pipeline Documentation

## Overview (v2.0.0)

The **PPP-Q Incremental ML Pipeline** is an automated workflow that runs every 15 days to:
- Fetch ONLY new economic and market data (not re-fetch everything)
- Append new rows to the existing consolidated dataset
- Preprocess data with **39 features** including egg/milk commodity basket
- **Train 10 multi-output models** (2 classifiers + 8 component regressors)
- **Apply horizon-aware predictions** (dynamic adjustments for 1Y-10Y investments)
- Automatically deploy if performance improves
- Send email notifications to stakeholders

This approach is **resource-efficient** and **time-saving** compared to full retrains that re-fetch 10+ years of historical data.

---

## v2.0.0 Major Enhancements

### ğŸš€ Multi-Output ML Architecture

**Classification Stage** (Ensemble):
- **LightGBM Classifier:** 96.5% Macro F1 (40% weight)
- **XGBoost Classifier:** 96.7% Macro F1 (60% weight)
- **Ensemble:** 96.30% Macro F1 on test set

**Regression Stage** (8 Component Scores):
- **8 LightGBM Regressors:** 99.3% avg RÂ² on test set
- Each predicts a component score (0-100)
- Weighted composite determines final class

### ğŸ“Š Component Scores (NEW in v2.0.0)

| Component | Weight | What It Measures | Model | RÂ² |
|-----------|--------|------------------|-------|-----|
| **Real Purchasing Power** | 25% | PP preservation vs inflation | LightGBM | 99.5% |
| **Volatility Risk** | 20% | Price stability (inverse volatility) | LightGBM | 99.2% |
| **Market Cycle** | 15% | Buy-low opportunity (distance from ATH) | LightGBM | 98.8% |
| **Growth Potential** | 15% | Future appreciation (market cap saturation) | LightGBM | 99.1% |
| **Consistency** | 10% | Return reliability over time | LightGBM | 98.5% |
| **Recovery** | 10% | Bounce-back speed from crashes | LightGBM | 98.2% |
| **Risk-Adjusted** | 15% | Returns per unit of risk (Sharpe-like) | LightGBM | 99.0% |
| **Commodity Score** | 5% | PP vs eggs & milk basket (NEW!) | LightGBM | 99.4% |

### ğŸ¯ Horizon-Aware Predictions

**Feature Adjustments** based on investment timeframe:

| Adjustment Type | 1-Year Horizon | 5-Year Horizon | 10-Year Horizon |
|----------------|----------------|----------------|-----------------|
| **Volatility Weight** | High (25%) | Medium (20%) | Low (15%) - time diversifies |
| **Growth Weight** | Low (10%) | Medium (15%) | High (20%) - compounding |
| **Cycle Weight** | High (20%) | Medium (15%) | Low (10%) - less relevant |
| **PP Multiplier** | 1Y used | 5Y used | 10Y used |

**Example**: Bitcoin volatile short-term â†’ C_ERODER at 1Y, but A_PRESERVER at 10Y

### ğŸ¥š Commodity Features (NEW)

5 new features tracking real-world purchasing power:

1. **Eggs_Per_100USD**: How many dozen eggs $100 can buy
2. **Milk_Gallons_Per_100USD**: How many gallons of milk $100 can buy
3. **Real_Return_Eggs_1Y**: 1-year return vs egg price inflation
4. **Real_Return_Milk_1Y**: 1-year return vs milk price inflation
5. **Real_Commodity_Basket_Return_1Y**: Blended egg/milk performance

**Why**: Eggs and milk are universal consumer staples that everyone buys. Better indicator of real purchasing power than abstract inflation metrics.

---

## Architecture

### Components

```
src/pipelines/
â”œâ”€â”€ pipeline_config.py      # Central configuration (paths, params, assets)
â”œâ”€â”€ notifications.py        # Email notifications to ba8616127@gmail.com
â”œâ”€â”€ model_registry.py       # MLflow model versioning + MODEL_ARTIFACTS_V2
â”œâ”€â”€ prefect_flows.py        # Main Prefect orchestration (v2.0.0 updated)
â””â”€â”€ __init__.py

src/models/
â”œâ”€â”€ pppq_multi_output_model.py  # v2.0.0 training script (10 models)
â””â”€â”€ train_lgb_xgb.py            # DEPRECATED (v1.x)
```

### Task Flow (v2.0.0)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚            INCREMENTAL PIPELINE v2.0.0                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                  â”‚
â”‚  TASK 1: FETCH NEW DATA (Incremental)                          â”‚
â”‚  â”œâ”€ Check last_date in final_consolidated_dataset.csv          â”‚
â”‚  â”œâ”€ Fetch ONLY data from APIs where Date > last_date            â”‚
â”‚  â”œâ”€ Feature engineer new rows (39 features with commodities)    â”‚
â”‚  â”œâ”€ Append to existing consolidated CSV                         â”‚
â”‚  â””â”€ Return: (complete_data, new_rows_count, new_data_only)     â”‚
â”‚                           â†“                                      â”‚
â”‚  TASK 2: PREPROCESS DATA (Incremental)                         â”‚
â”‚  â”œâ”€ Process only NEW rows                                       â”‚
â”‚  â”œâ”€ Feature extraction for PPPQ (39 features total)             â”‚
â”‚  â”œâ”€ Calculate 8 component score targets                         â”‚
â”‚  â”œâ”€ Append to train/val/test splits based on date ranges        â”‚
â”‚  â””â”€ Return: (train_df, val_df, test_df)                         â”‚
â”‚                           â†“                                      â”‚
â”‚  TASK 3: TRAIN MULTI-OUTPUT MODELS (v2.0.0)                    â”‚
â”‚  â”œâ”€ Train 2 Classifiers (LightGBM + XGBoost)                   â”‚
â”‚  â”œâ”€ Train 8 Component Regressors (LightGBM)                    â”‚
â”‚  â”œâ”€ Validate all 10 models created                             â”‚
â”‚  â”œâ”€ Load metrics from training_metrics_v2.json                 â”‚
â”‚  â””â”€ Return: Classification F1 + Component RÂ² metrics            â”‚
â”‚                           â†“                                      â”‚
â”‚  TASK 4: EVALUATE & VERSION (MLflow)                           â”‚
â”‚  â”œâ”€ Evaluate classification ensemble (96.3% F1)                â”‚
â”‚  â”œâ”€ Evaluate component regressors (99.3% avg RÂ²)               â”‚
â”‚  â”œâ”€ Compare with previous best model                            â”‚
â”‚  â”œâ”€ Register with MLflow (v2.0.0 metadata)                     â”‚
â”‚  â”œâ”€ Decide deployment based on F1 threshold                    â”‚
â”‚  â””â”€ Return: Evaluation metrics, deploy decision                 â”‚
â”‚                           â†“                                      â”‚
â”‚  TASK 5: SEND NOTIFICATIONS (Email)                            â”‚
â”‚  â”œâ”€ Notify pipeline start                                       â”‚
â”‚  â”œâ”€ Notify success/failure                                      â”‚
â”‚  â”œâ”€ Include v2.0.0 metrics (10 models, Classification F1,      â”‚
â”‚  â”‚   Component Avg RÂ², Commodity Score)                        â”‚
â”‚  â””â”€ Send to: ba8616127@gmail.com                                â”‚
â”‚                                                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## How It Works

### 1ï¸âƒ£ Data Ingestion (INCREMENTAL)

**File:** `src/pipelines/prefect_flows.py` â†’ `fetch_new_data()`

#### Logic Flow:
```python
# 1. Check existing data
if final_consolidated_dataset.csv exists:
    last_date = max(Date) in CSV
    existing_rows = count of rows
else:
    last_date = None (first run)

# 2. Fetch fresh data from all sources
df_economic = fetch_economic_data()           # FRED API
df_assets = fetch_asset_and_vix_prices()      # Yahoo Finance
df_crypto = fetch_crypto_data_yfinance()      # Yahoo Finance
df_commodities = fetch_real_baselines()       # FRED API
df_global = fetch_global_market_data()        # World Bank API

# NEW in v2.0.0: Commodity prices (eggs & milk)
df_commodity_prices = fetch_commodity_prices()  # BLS API or manual

# 3. Merge all sources
df_merged = merge_all_raw_data(...)

# 4. FILTER TO ONLY NEW DATA
if last_date is not None:
    df_new_only = df_merged[df_merged['Date'] > last_date]
    new_rows = len(df_new_only)
else:
    df_new_only = df_merged  # first run
    new_rows = len(df_new_only)

# 5. Feature engineering on NEW data (39 features)
df_new_featured = engineer_features(df_new_only)

# NEW in v2.0.0: Add commodity features
df_new_featured = add_commodity_features(df_new_featured, df_commodity_prices)

# 6. Append to existing CSV
if existing_data:
    df_combined = concat([existing_df, df_new_featured])
    df_combined.drop_duplicates(subset=['Date'])
    df_combined.to_csv(final_consolidated_dataset.csv)
else:
    df_new_featured.to_csv(final_consolidated_dataset.csv)

# 7. Return complete data + new data
return df_combined, new_rows, df_new_featured
```

#### Data Sources:
| Source | Data Type | API | Update Frequency |
|--------|-----------|-----|------------------|
| FRED | Economic indicators (inflation, GDP, unemployment) | https://fred.stlouisfed.org | Daily |
| Yahoo Finance | Stock prices, crypto prices, VIX | yfinance library | Daily |
| World Bank | Global M2, Global GDP | World Bank API | Monthly |
| CoinGecko | Crypto supply data | Free API | Daily |
| **BLS** (NEW) | **Egg & milk prices** | Manual or BLS API | Monthly |

#### New Data Detection:
- **First Run:** Fetches all historical data
- **Subsequent Runs:** Only fetches data where `Date > last_date_in_csv`
- **No New Data:** Pipeline skips (no wasted compute)

---

### 2ï¸âƒ£ Preprocessing (INCREMENTAL)

**File:** `src/pipelines/prefect_flows.py` â†’ `preprocess_data()`

#### What Gets Processed:
```python
# Input: Complete dataset + new_rows_count + df_new_only
def preprocess_data(df_raw, new_rows_count, df_new_only):

    # If no new data: return existing splits
    if new_rows_count == 0:
        return (train_df, val_df, test_df)  # load from disk

    # Otherwise: process ALL data but focus on NEW rows

    for each asset in CORE_ASSETS:
        # Create asset-specific row for each date
        # Extract features (39 total):
        # - Real returns (3Y, 5Y, 10Y)
        # - PP multipliers (1Y, 5Y, 10Y)
        # - Volatility (90D)
        # - Sharpe ratio (5Y)
        # - Max drawdown
        # - Distance from ATH
        # - Distance from MA200
        # - Market cap saturation
        # - Composite score
        # - Stability & consistency metrics
        # - Commodity features (eggs, milk) â† NEW!

        # NEW in v2.0.0: Calculate 8 component score targets
        targets = {
            'real_pp_score': calculate_real_pp_score(row),
            'volatility_score': calculate_volatility_score(row),
            'cycle_score': calculate_cycle_score(row),
            'growth_score': calculate_growth_score(row),
            'consistency_score': calculate_consistency_score(row),
            'recovery_score': calculate_recovery_score(row),
            'risk_adjusted_score': calculate_risk_adjusted_score(row),
            'commodity_score': calculate_commodity_score(row)  # NEW!
        }

        # Calculate PPP_Q_Composite_Score (weighted from components)
        # Assign PPP_Q_Class: A_PRESERVER, B_PARTIAL, C_ERODER, D_DESTROYER

    # Time-based splits (NO LEAKAGE)
    train_df = data where TRAIN_START <= Date <= TRAIN_END
    val_df   = data where VAL_START <= Date <= VAL_END
    test_df  = data where TEST_START <= Date <= TEST_END

    # Save to CSV
    train_df.to_csv(data/processed/pppq/train/)
    val_df.to_csv(data/processed/pppq/val/)
    test_df.to_csv(data/processed/pppq/test/)

    return (train_df, val_df, test_df)
```

#### Asset Categories:
```python
CORE_ASSETS = {
    'Bitcoin': crypto,
    'Ethereum': crypto,
    'Gold': precious_metal,
    'Silver': precious_metal,
    'WTI_Crude': commodity,
    'Natural_Gas': commodity,
    'S&P_500': equity_index,
    'Nasdaq_100': equity_index,
    'AAPL': tech_stock,
    'MSFT': tech_stock,
    'NVDA': tech_stock,
    'TESLA': tech_stock,
}
```

#### PPP_Q Classes (Dynamic Thresholds):
| Class | Base Score | Crypto Threshold | Metal Threshold | Index Threshold |
|-------|------------|------------------|-----------------|-----------------|
| **A_PRESERVER** | â‰¥65 | â‰¥70 | â‰¥62 | â‰¥65 |
| **B_PARTIAL** | 55-64 | 58-69 | 52-61 | 55-64 |
| **C_ERODER** | 42-54 | 45-57 | 40-51 | 42-54 |
| **D_DESTROYER** | <42 | <45 | <40 | <42 |

*Note: Thresholds adjust based on asset category and investment horizon*

---

### 3ï¸âƒ£ Model Training (v2.0.0 - Multi-Output)

**File:** `src/models/pppq_multi_output_model.py` (called by prefect_flows.py)

#### Models Trained (10 Total):

**Classification Models (2)**:
1. **LightGBM Classifier**
   - Params: `num_leaves=31, learning_rate=0.05, num_iterations=500`
   - Performance: 96.5% Macro F1, best iteration=186
   - Weight in ensemble: 40%

2. **XGBoost Classifier**
   - Params: `max_depth=7, learning_rate=0.05, n_estimators=500`
   - Performance: 96.7% Macro F1
   - Weight in ensemble: 60%

**Component Regression Models (8 LightGBM Regressors)**:
3. Real Purchasing Power Score (99.5% RÂ²)
4. Volatility Risk Score (99.2% RÂ²)
5. Market Cycle Score (98.8% RÂ²)
6. Growth Potential Score (99.1% RÂ²)
7. Consistency Score (98.5% RÂ²)
8. Recovery Score (98.2% RÂ²)
9. Risk-Adjusted Score (99.0% RÂ²)
10. **Commodity Score (99.4% RÂ²)** â† NEW in v2.0.0!

#### Training Output:
```
models/pppq/
â”œâ”€â”€ lgbm_classifier.txt                              # Classification ensemble (40%)
â”œâ”€â”€ xgb_classifier.json                              # Classification ensemble (60%)
â”œâ”€â”€ lgbm_target_real_pp_score_regressor.txt         # Component 1
â”œâ”€â”€ lgbm_target_volatility_score_regressor.txt      # Component 2
â”œâ”€â”€ lgbm_target_cycle_score_regressor.txt           # Component 3
â”œâ”€â”€ lgbm_target_growth_score_regressor.txt          # Component 4
â”œâ”€â”€ lgbm_target_consistency_score_regressor.txt     # Component 5
â”œâ”€â”€ lgbm_target_recovery_score_regressor.txt        # Component 6
â”œâ”€â”€ lgbm_target_risk_adjusted_score_regressor.txt   # Component 7
â”œâ”€â”€ lgbm_target_commodity_score_regressor.txt       # Component 8 (NEW!)
â”œâ”€â”€ feature_columns.json                             # 39 features
â”œâ”€â”€ label_encoder.pkl                                # Class encoder
â”œâ”€â”€ model_registry.json                              # MLflow tracking
â””â”€â”€ training_metrics_v2.json                         # v2.0.0 metrics
```

---

### 4ï¸âƒ£ Evaluation & Deployment

**File:** `src/pipelines/prefect_flows.py` â†’ `evaluate_and_version()`

#### Metrics Tracked (v2.0.0):
```python
# Classification metrics
classification_metrics = {
    'macro_f1': 0.963,              # Primary deployment metric
    'accuracy': 0.965,
    'balanced_accuracy': 0.962,
    'precision_per_class': {...},
    'recall_per_class': {...},
    'f1_per_class': {...}
}

# Component regression metrics (NEW)
component_metrics = {
    'avg_r2': 0.993,                # Average across 8 regressors
    'min_r2': 0.982,                # Worst performer (Recovery)
    'max_r2': 0.995,                # Best performer (Real PP)
    'rmse_avg': 1.2,
    'individual_scores': {
        'real_pp_score_r2': 0.995,
        'volatility_score_r2': 0.992,
        'cycle_score_r2': 0.988,
        'growth_score_r2': 0.991,
        'consistency_score_r2': 0.985,
        'recovery_score_r2': 0.982,
        'risk_adjusted_score_r2': 0.990,
        'commodity_score_r2': 0.994   # NEW!
    }
}
```

#### Deployment Decision Logic:
```python
# Auto-deploy if:
1. New classification F1 > previous best + 0.001  (0.1% improvement)
2. Classification F1 > 0.90 (90% minimum)
3. Component avg RÂ² > 0.95 (95% minimum)

# MLflow Tracking (v2.0.0):
- Register model with version number
- Tag with:
  * version: '2.0.0'
  * num_models: 10
  * classifiers: 2
  * regressors: 8
  * classification_f1: 0.963
  * component_avg_r2: 0.993
  * new_data_count: X
  * deployment_date: timestamp

# Production Ready:
- Deployed models saved to: models/pppq/
- API served from: src/api/main.py (predict_ml.py)
- Endpoint: POST /predict
```

---

### 5ï¸âƒ£ Notifications (v2.0.0 Updated)

**File:** `src/pipelines/notifications.py`

#### Notification Types:

**ğŸ“§ Pipeline Start**
```
Subject: ğŸš€ PPP-Q Pipeline v2.0.0 Started
To: ba8616127@gmail.com
Content: Pipeline execution started at [timestamp]
```

**ğŸ“§ Pipeline Success (v2.0.0)**
```
Subject: âœ… PPP-Q Pipeline v2.0.0 Completed Successfully
To: ba8616127@gmail.com

Details:
- Model Version: v2.0.0 (Multi-Output)
- Models Trained: 10 (2 classifiers + 8 regressors)
- New Data Rows: 150
- Classification F1: 0.9630 (96.30%)
- Classification Accuracy: 0.9650
- Component Avg RÂ²: 0.9930 (99.30%)
- Commodity Score RÂ²: 0.9940 (NEW!)
- Deployed: âœ… Yes
- Run ID: pppq-v2-20241217
```

**ğŸ“§ Pipeline Failure**
```
Subject: âŒ PPP-Q Pipeline v2.0.0 Failed
To: ba8616127@gmail.com

Error: [error message]
Time: [timestamp]
Failed Task: [task name]
```

**ğŸ“§ Model Deployed (v2.0.0)**
```
Subject: ğŸš€ New Multi-Output Model Deployed to Production
To: ba8616127@gmail.com

Model Version: pppq-v2-20241217
Architecture: Multi-Output (2 classifiers + 8 regressors)
Classification F1: 0.9630
Component Avg RÂ²: 0.9930
Models Deployed: 10
```

---

## Running the Pipeline

### Manual Execution

**Incremental Update (default)**
```bash
python -c "from src.pipelines.prefect_flows import run_pipeline; run_pipeline()"
```
Fetches only new data since last run, trains all 10 models.

**Force Full Retrain**
```bash
python -c "from src.pipelines.prefect_flows import run_pipeline; run_pipeline(force_full_retrain=True)"
```
Retrains even if no new data available.

**Scheduled Execution**
```bash
python -c "from src.pipelines.prefect_flows import schedule_pipeline; schedule_pipeline()"
```
Runs every 15 days automatically.

### Automated Execution

**Via GitHub Actions** (every 15 days)
- Workflow: `.github/workflows/automated-pipeline.yml`
- Schedule: `0 2 */15 * *` (every 15 days at 2 AM UTC)
- Runs on: `ubuntu-latest`
- Steps:
  1. Checkout code with Git LFS
  2. Set up Python 3.10
  3. Install dependencies
  4. Run data collection
  5. Run preprocessing (v2.0.0 with 39 features)
  6. Train multi-output models (10 models)
  7. Validate all models exist
  8. Commits updated data/models (Git LFS)
  9. Pushes to repository
  10. Send notification

---

## Configuration

### Environment Variables (.env)

```bash
# API Keys
FRED_API_KEY=your_fred_api_key
YAHOO_FINANCE_API_KEY=optional
BLS_API_KEY=optional  # NEW in v2.0.0 for egg/milk prices

# Email Notification
SMTP_SERVER=smtp.gmail.com
SMTP_PORT=587
SENDER_EMAIL=your_email@gmail.com
SENDER_PASSWORD=your_app_password
RECIPIENT_EMAIL=ba8616127@gmail.com

# Prefect Cloud (optional)
PREFECT_API_KEY=your_prefect_api_key
PREFECT_API_URL=https://api.prefect.cloud/api

# MLflow
MLFLOW_TRACKING_URI=file:./mlruns
```

### Model Registry (v2.0.0)

```python
# NEW in v2.0.0: Tracks all 10 models
MODEL_ARTIFACTS_V2 = {
    # Classifiers
    'lgbm_classifier': 'models/pppq/lgbm_classifier.txt',
    'xgb_classifier': 'models/pppq/xgb_classifier.json',

    # Component Regressors
    'lgbm_real_pp': 'models/pppq/lgbm_target_real_pp_score_regressor.txt',
    'lgbm_volatility': 'models/pppq/lgbm_target_volatility_score_regressor.txt',
    'lgbm_cycle': 'models/pppq/lgbm_target_cycle_score_regressor.txt',
    'lgbm_growth': 'models/pppq/lgbm_target_growth_score_regressor.txt',
    'lgbm_consistency': 'models/pppq/lgbm_target_consistency_score_regressor.txt',
    'lgbm_recovery': 'models/pppq/lgbm_target_recovery_score_regressor.txt',
    'lgbm_risk_adjusted': 'models/pppq/lgbm_target_risk_adjusted_score_regressor.txt',
    'lgbm_commodity': 'models/pppq/lgbm_target_commodity_score_regressor.txt'
}
```

---

## Data Flow Diagram (v2.0.0)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  External Data Sources                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  FRED    Yahoo Finance    World Bank    CoinGecko    BLS (NEW)     â”‚
â”‚  â””â”€Econ   â””â”€Prices        â””â”€Global M2   â””â”€Supply    â””â”€Eggs/Milk    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  TASK 1: FETCH NEW DATA                                             â”‚
â”‚  â””â”€ Filters to dates > last_date                                    â”‚
â”‚  â””â”€ Features engineering (39 features with commodities)             â”‚
â”‚  â””â”€ Appends to final_consolidated_dataset.csv                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  data/raw/final_consolidated_dataset.csv                            â”‚
â”‚  (Complete historical + new rows with commodity data)               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  TASK 2: PREPROCESS DATA (v2.0.0)                                   â”‚
â”‚  â””â”€ Asset-level feature extraction (39 features)                    â”‚
â”‚  â””â”€ Calculate 8 component score targets                             â”‚
â”‚  â””â”€ PPP_Q classification labels                                     â”‚
â”‚  â””â”€ Time-based splits (train/val/test)                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  data/processed/pppq/                                               â”‚
â”‚  â”œâ”€ train/pppq_train.csv    (2015-2022, 39 features, 9 targets)   â”‚
â”‚  â”œâ”€ val/pppq_val.csv        (2023-06, 39 features, 9 targets)     â”‚
â”‚  â””â”€ test/pppq_test.csv      (2023-12, 39 features, 9 targets)     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  TASK 3: TRAIN MULTI-OUTPUT MODELS (v2.0.0)                         â”‚
â”‚  â””â”€ 2 Classification Models (LightGBM + XGBoost ensemble)           â”‚
â”‚  â””â”€ 8 Component Regression Models (LightGBM)                        â”‚
â”‚  â””â”€ Total: 10 models trained                                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  models/pppq/ (10 model files)                                      â”‚
â”‚  â”œâ”€ lgbm_classifier.txt                                             â”‚
â”‚  â”œâ”€ xgb_classifier.json                                             â”‚
â”‚  â”œâ”€ lgbm_target_*_score_regressor.txt (8 regressors)               â”‚
â”‚  â”œâ”€ training_metrics_v2.json (NEW - v2.0.0 metrics)                â”‚
â”‚  â””â”€ model_registry.json (MLflow tracking)                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  TASK 4: EVALUATE & VERSION                                         â”‚
â”‚  â””â”€ Classification F1: 96.30%                                       â”‚
â”‚  â””â”€ Component Avg RÂ²: 99.30%                                        â”‚
â”‚  â””â”€ Compare with previous best                                      â”‚
â”‚  â””â”€ Register with MLflow if better                                  â”‚
â”‚  â””â”€ Decide auto-deployment                                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  TASK 5: SEND NOTIFICATIONS (v2.0.0)                                â”‚
â”‚  â””â”€ Email to ba8616127@gmail.com                                    â”‚
â”‚  â””â”€ Metrics: 10 models, F1=96.3%, RÂ²=99.3%, commodity score        â”‚
â”‚  â””â”€ New data stats, deployment info                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Monitoring & Troubleshooting

### Pipeline Logs
```bash
# View recent pipeline logs
cat logs/pipeline.log

# Follow real-time logs (if running)
tail -f logs/pipeline.log
```

### Check Data Freshness
```bash
# Last date in consolidated dataset
python -c "
import pandas as pd
df = pd.read_csv('data/raw/final_consolidated_dataset.csv')
print(f'Total rows: {len(df)}')
print(f'Date range: {df[\"Date\"].min()} to {df[\"Date\"].max()}')
print(f'Features: {len(df.columns)}')
"
```

### Check Model Performance (v2.0.0)
```bash
# View v2.0.0 metrics
cat models/pppq/training_metrics_v2.json | python -m json.tool

# Validate all 10 models exist
python -c "
from pathlib import Path
models_dir = Path('models/pppq')
required = [
    'lgbm_classifier.txt',
    'xgb_classifier.json',
    'lgbm_target_real_pp_score_regressor.txt',
    'lgbm_target_volatility_score_regressor.txt',
    'lgbm_target_cycle_score_regressor.txt',
    'lgbm_target_growth_score_regressor.txt',
    'lgbm_target_consistency_score_regressor.txt',
    'lgbm_target_recovery_score_regressor.txt',
    'lgbm_target_risk_adjusted_score_regressor.txt',
    'lgbm_target_commodity_score_regressor.txt'
]
missing = [m for m in required if not (models_dir / m).exists()]
print(f'âœ“ All 10 models exist' if not missing else f'âŒ Missing: {missing}')
"
```

### Common Issues (v2.0.0)

| Issue | Solution |
|-------|----------|
| **No new data detected** | Check FRED/Yahoo APIs are accessible. Date parsing issue? |
| **Missing commodity data** | Verify BLS API key or update manual commodity prices |
| **Preprocessing fails** | Check 39 features exist. Missing egg/milk columns? |
| **Model training slow** | Expected ~45 seconds for 10 models. Check hardware. |
| **Missing models after training** | Run `python src/models/pppq_multi_output_model.py` manually |
| **Email not sending** | Verify SMTP credentials in .env. Gmail needs app password. |
| **GitHub Actions fails** | Check secrets are set. FRED_API_KEY in repo settings? |
| **Git LFS errors** | Install git-lfs: `git lfs install`, track models: `git lfs track "models/pppq/*.txt"` |

---

## Performance Metrics (v2.0.0)

### Typical Pipeline Runtime
- **Data Ingestion:** 2-5 minutes (depends on API response times)
- **Preprocessing:** 1-2 minutes (70 assets Ã— dates, 39 features)
- **Model Training:** 45-90 seconds (10 models with early stopping)
- **Evaluation:** 30 seconds
- **Notifications:** 5 seconds
- **Total:** ~5-10 minutes (much faster than v1.x!)

### Model Performance (v2.0.0 Production)

**Classification**:
- **Ensemble Macro F1:** 96.30% (96.5% LGBM + 96.7% XGB)
- **Accuracy:** 96.5%
- **Balanced Accuracy:** 96.2%

**Regression (Component Scores)**:
- **Average RÂ²:** 99.3% across 8 regressors
- **Best Performer:** Real PP Score (99.5% RÂ²)
- **NEW:** Commodity Score (99.4% RÂ²)
- **Average RMSE:** 1.2 points (on 0-100 scale)

### Improvement vs v1.x

| Metric | v1.x | v2.0.0 | Improvement |
|--------|------|--------|-------------|
| Classification F1 | 78% | 96.3% | +18.3% |
| Num Models | 3 | 10 | +233% |
| Features | 18 | 39 | +117% |
| Interpretability | Low | High | Component scores! |
| Horizon Awareness | No | Yes | Dynamic |
| Commodity Tracking | No | Yes | Eggs & milk |

---

## Files Modified by Pipeline (v2.0.0)

Each run updates:
```
data/raw/
  â””â”€ final_consolidated_dataset.csv          â† NEW ROWS APPENDED

data/processed/pppq/
  â”œâ”€ train/pppq_train.csv                    â† Updated (39 features)
  â”œâ”€ val/pppq_val.csv                        â† Updated (39 features)
  â”œâ”€ test/pppq_test.csv                      â† Updated (39 features)
  â”œâ”€ pppq_features.json                      â† Feature list (39)
  â”œâ”€ pppq_summary.json                       â† Dataset stats
  â””â”€ pppq_thresholds.json                    â† Dynamic thresholds

models/pppq/
  â”œâ”€ lgbm_classifier.txt                     â† NEW classification model
  â”œâ”€ xgb_classifier.json                     â† NEW classification model
  â”œâ”€ lgbm_target_real_pp_score_regressor.txt           â† NEW regressor
  â”œâ”€ lgbm_target_volatility_score_regressor.txt       â† NEW regressor
  â”œâ”€ lgbm_target_cycle_score_regressor.txt            â† NEW regressor
  â”œâ”€ lgbm_target_growth_score_regressor.txt           â† NEW regressor
  â”œâ”€ lgbm_target_consistency_score_regressor.txt      â† NEW regressor
  â”œâ”€ lgbm_target_recovery_score_regressor.txt         â† NEW regressor
  â”œâ”€ lgbm_target_risk_adjusted_score_regressor.txt    â† NEW regressor
  â”œâ”€ lgbm_target_commodity_score_regressor.txt        â† NEW regressor
  â”œâ”€ label_encoder.pkl                       â† Class encoder
  â”œâ”€ feature_columns.json                    â† 39 features
  â”œâ”€ model_registry.json                     â† MLflow history (v2.0.0)
  â”œâ”€ training_metrics_v2.json                â† v2.0.0 metrics
  â””â”€ training_summary.json                   â† Training summary

logs/
  â””â”€ pipeline.log                            â† Execution log
```

---

## Next Steps & Improvements

### Completed (v2.0.0) âœ…
- [x] Multi-output architecture (2 classifiers + 8 regressors)
- [x] Horizon-aware predictions (1Y-10Y dynamic adjustments)
- [x] Commodity features (eggs & milk purchasing power)
- [x] Ensemble classification (LightGBM + XGBoost)
- [x] Component score explainability
- [x] Dynamic class thresholds (asset category + horizon)
- [x] Model versioning with MLflow
- [x] Automated workflows (GitHub Actions)
- [x] Git LFS for model files

### Future Enhancements
- [ ] Real-time BLS API integration (automate egg/milk price fetching)
- [ ] SHAP values for feature importance explanations
- [ ] Hyperparameter tuning with Optuna (auto-optimize model params)
- [ ] Data drift detection (alert if input distribution changes)
- [ ] A/B testing framework (compare v2 vs v3 in production)
- [ ] Kubernetes deployment (scale horizontally)
- [ ] Additional commodity baskets (bread, housing, gasoline)
- [ ] Sentiment analysis (news + social media for market cycle)
- [ ] On-chain metrics (Bitcoin network health indicators)

---

## Documentation References

For deeper understanding of v2.0.0:

- **Complete ML System Guide**: [docs/COMPLETE_ML_SYSTEM_GUIDE.md](docs/COMPLETE_ML_SYSTEM_GUIDE.md)
  - Every model explained step-by-step
  - Feature engineering rationale
  - Real-world examples
  - Dynamic threshold logic

- **Workflow Updates**: [docs/WORKFLOW_UPDATES_v2.md](docs/WORKFLOW_UPDATES_v2.md)
  - GitHub Actions changes
  - Prefect orchestration updates
  - Deployment checklist

- **Prefect v2.0.0**: [docs/PREFECT_V2_UPDATE.md](docs/PREFECT_V2_UPDATE.md)
  - Multi-output training integration
  - Model validation
  - Notification changes

---

**Last Updated:** December 17, 2024 (v2.0.0)
**Maintainer:** Bilal Ahmad Sheikh (GIKI)
**Pipeline Type:** Incremental | **Frequency:** Every 15 days
**Notification:** Email to ba8616127@gmail.com
**Architecture:** Multi-Output (2 Classifiers + 8 Regressors)
**Performance:** 96.3% Classification F1, 99.3% Component RÂ²
